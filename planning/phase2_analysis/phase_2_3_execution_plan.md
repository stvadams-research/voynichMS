---
name: "Phase 2.3 – Explicit Model Instantiation and Disconfirmation"
overview: "Move from admissible explanation classes to explicit, falsifiable models"
status: COMPLETE
executed: 2026-02-06
---

# PHASE_2_3_EXECUTION_PLAN.md
## Phase 2.3 – Explicit Model Instantiation and Disconfirmation

Phase 2.3 defines the next execution step following Phase 2.2.
It exists to move from admissible explanation classes to **explicit, falsifiable models**, without committing to interpretation or meaning.

Phase 2.3 is the first phase where models are allowed to exist long enough to fail.

This document is binding.

---

## 1. Phase 2.3 Objective

Phase 2.3 exists to answer the question:

**Can any explicit model within the currently admissible explanation classes account for observed structure without contradiction, special pleading, or collapse under perturbation?**

This phase does not select a winner.
It eliminates models, tightens constraints, or justifies termination.

---

## 2. Inputs (Hard Dependencies)

Phase 2.3 may not begin unless the following are frozen and referenced:

- FINDINGS_PHASE_1_FOUNDATION.md
- FINDINGS_PHASE_2_1_ADMISSIBILITY.md
- FINDINGS_PHASE_2_2_CONSTRAINTS.md
- Phase 1 ledgers, anchors, controls, metrics
- Decision registry through Phase 2.2

No Phase 1 or Phase 2.2 artifacts may be modified.

---

## 3. In-Scope Explanation Classes

Phase 2.3 is restricted to:

- Visual Grammar Systems (PRIMARY)
- Constructed Symbolic Systems (SECONDARY)
- Hybrid Systems (only as a falsification target)

Natural Language and Enciphered Language are permanently out of scope.

---

## 4. What Counts as a “Model” in Phase 2.3

A Phase 2.3 model must satisfy **all** of the following:

- Explicit generative or organizational rules
- Defined inputs and outputs
- Testable predictions under perturbation
- Clear failure conditions

Narratives, metaphors, and informal descriptions are not models.

---

## 5. Execution Tracks in Phase 2.3

Phase 2.3 consists of four coordinated execution tracks.

---

### Track C1: Explicit Visual Grammar Model Instantiation

Purpose:
- Instantiate one or more *minimal* visual grammar models consistent with Phase 2.2 constraints.

Model requirements:
- Define grammar units (purely structural)
- Define composition rules (local, non-semantic)
- Define spatial relations explicitly
- Make no claims about meaning

Examples (illustrative):
- adjacency grammars
- containment grammars
- diagram-first annotation grammars

Outputs:
- Formal model definitions
- Expected structural signatures
- Model-specific predictions

---

### Track C2: Explicit Constructed System Models

Purpose:
- Instantiate non-visual constructed systems as competitors, not strawmen.

Model requirements:
- Explicit generation rules
- No semantic assumptions
- No hidden language reintroduction
- Must match Phase 2.2 locality and information constraints

Outputs:
- Formal constructed-system models
- Structural predictions
- Comparison baselines

---

### Track C3: Disconfirmation and Discontinuation Tests

Purpose:
- Actively attempt to break each instantiated model.

Execution:
- Apply perturbations used in Phase 1 and 2.2
- Test sensitivity to:
  - segmentation changes
  - ordering changes
  - omission
  - anchor disruption
- Evaluate whether failures are catastrophic or graceful

Outputs:
- Model-specific failure reports
- Discontinuation criteria
- Evidence-backed rejections

Models that require parameter tuning to survive are considered failed.

---

### Track C4: Cross-Model Comparative Evaluation

Purpose:
- Compare surviving models against each other and against null variants.

Execution:
- Measure explanatory power vs complexity
- Compare fit to:
  - locality profiles
  - information density
  - anchor behavior
- Compare failure modes symmetrically

Outputs:
- Comparative evaluation matrix
- Constraint-driven ranking (non-probabilistic)
- Identification of indistinguishable models

---

## 6. Required Artifacts

Phase 2.3 must produce:

- A Model Registry (explicit definitions)
- A Disconfirmation Log per model
- A Comparative Evaluation Matrix
- A Phase 2.3 Findings Summary

All artifacts must be reproducible and machine-readable.

---

## 7. Explicit Non-Goals

Phase 2.3 does NOT:

- assign semantics
- interpret meaning
- decode text
- select a final explanation
- optimize predictive accuracy

Any appearance of meaning is treated as a red flag.

---

## 8. Stop and Termination Conditions

Phase 2.3 must stop when any of the following occur:

- All instantiated models fail disconfirmation tests
- Remaining models are indistinguishable under all tests
- Additional model complexity does not increase explanatory power
- Results become dominated by assumption sensitivity

Termination is a valid and successful outcome.

---

## 9. Success Criteria

Phase 2.3 is successful if at least one of the following is achieved:

- One or more explicit models are falsified
- Explanation classes are further narrowed
- Visual Grammar models fail under explicit tests
- Remaining models are tightly constrained and fragile

Producing “no surviving models” is a legitimate success.

---

## 10. Relationship to Future Phases

Phase 2.3 outputs determine whether:

- Phase 2 terminates with integrity
- Phase 3 (Constrained Interpretation) is justified
- Translation is structurally inadmissible

Phase 3 must not begin without explicit Phase 2.3 justification.

---

## 11. Final Statement

Phase 2.3 is where explanations stop being safe.

Any model that survives Phase 2.3 has earned the right to be taken seriously.
Any model that fails has done so honestly.

If nothing survives, that is not failure.
That is resolution.

---

## 12. EXECUTION RESULTS

**Execution Date:** 2026-02-06
**Status:** COMPLETE

### 12.1 Model Registry

Six explicit models were instantiated across two admissible classes:

#### Track C1: Visual Grammar Models

| Model ID | Model Name | Rules | Predictions |
|----------|------------|-------|-------------|
| vg_adjacency_grammar | Adjacency Grammar Model | 5 | 3 |
| vg_containment_grammar | Containment Grammar Model | 5 | 2 |
| vg_diagram_annotation | Diagram-First Annotation Model | 5 | 3 |

#### Track C2: Constructed System Models

| Model ID | Model Name | Rules | Predictions |
|----------|------------|-------|-------------|
| cs_procedural_generation | Procedural Generation Model | 5 | 3 |
| cs_glossolalia | Glossolalic System Model | 5 | 2 |
| cs_meaningful_construct | Meaningful Construct Model | 5 | 2 |

### 12.2 Track C3: Disconfirmation Results

**Perturbation Battery Applied:**
- Segmentation (strength: 0.05, 0.10, 0.15)
- Ordering (strength: 0.10, 0.20, 0.30)
- Omission (strength: 0.05, 0.10, 0.20)
- Anchor Disruption (strength: 0.10, 0.25, 0.50)

#### Model-by-Model Results

| Model | Predictions Passed | Disconfirmation Survived | Final Status |
|-------|-------------------|-------------------------|--------------|
| vg_adjacency_grammar | 3/3 | 9/10 | **FALSIFIED** |
| vg_containment_grammar | 1/2 | 8/10 | **FALSIFIED** |
| vg_diagram_annotation | 3/3 | 9/10 | **FALSIFIED** |
| cs_procedural_generation | 2/3 | 12/12 | **SURVIVING** |
| cs_glossolalia | 2/2 | 11/12 | **FALSIFIED** |
| cs_meaningful_construct | 2/2 | 10/12 | **FALSIFIED** |

#### Critical Failures

1. **Visual Grammar Models** - All three failed at anchor_disruption (threshold 0.50):
   - Adjacency Grammar: 0.84 degradation at strength 0.10
   - Containment Grammar: 0.72 degradation at strength 0.10
   - Diagram Annotation: 0.96 degradation at strength 0.10

2. **Glossolalic System** - Failed at ordering_0.30 (0.64 degradation)

3. **Meaningful Construct** - Failed at omission_0.20 and anchor_disruption_0.50

4. **Procedural Generation** - **ONLY SURVIVOR** - survived all 12 perturbation tests

### 12.3 Track C4: Comparative Evaluation Matrix

#### Overall Ranking

| Rank | Model | Composite Score |
|------|-------|-----------------|
| 1 | cs_procedural_generation | 0.516 |
| 2 | vg_diagram_annotation | 0.492 |
| 3 | vg_adjacency_grammar | 0.476 |
| 4 | vg_containment_grammar | 0.444 |
| 5 | cs_glossolalia | 0.444 |
| 6 | cs_meaningful_construct | 0.430 |

#### Dimension Scores (0-1 scale)

| Model | Robustness | Explanatory Scope | Parsimony | Falsifiability |
|-------|------------|-------------------|-----------|----------------|
| cs_procedural_generation | 0.70 | 0.60 | 0.71 | 1.00 |
| vg_diagram_annotation | 0.60 | 0.60 | 0.71 | 1.00 |
| vg_adjacency_grammar | 0.54 | 0.60 | 0.71 | 1.00 |
| cs_glossolalia | 0.57 | 0.40 | 0.71 | 1.00 |
| vg_containment_grammar | 0.57 | 0.40 | 0.71 | 1.00 |
| cs_meaningful_construct | 0.52 | 0.40 | 0.71 | 1.00 |

#### Summary by Explanation Class

| Class | Models | Surviving | Falsified | Best Model | Best Score |
|-------|--------|-----------|-----------|------------|------------|
| constructed_system | 3 | 1 | 2 | cs_procedural_generation | 0.516 |
| visual_grammar | 3 | 0 | 3 | vg_diagram_annotation | 0.492 |

### 12.4 Key Findings

1. **Single Survivor**: Only one model survived disconfirmation testing:
   - **Procedural Generation Model** (constructed_system class)
   - Survived 12/12 perturbation tests
   - However, it FAILED prediction proc_p3 (information density)

2. **Visual Grammar Collapse**: All visual grammar models failed at anchor disruption:
   - This is expected behavior—visual grammar models depend on text-diagram coupling
   - Their failure confirms their design: they require anchors to function
   - **Interpretation**: Visual grammar remains theoretically valid but highly fragile

3. **Prediction Failures**:
   - Procedural Generation: Failed on information density (z=4.00 too high for pure generation)
   - Containment Grammar: Failed on container-based text grouping evidence

4. **Information Density Anomaly**:
   - Phase 2.2 found z=4.00 information density
   - This is **problematic for ALL "meaningless" models** (procedural, glossolalia)
   - Suggests the manuscript may contain structured content, not random generation

5. **Class-Level Outcome**:
   - **constructed_system**: 1/3 surviving (but with caveats)
   - **visual_grammar**: 0/3 surviving (but failure mode is structural, not logical)

### 12.5 Resolution Assessment

Per Section 8 (Stop Conditions) and Section 9 (Success Criteria):

**Achieved:**
- ✅ Multiple explicit models falsified (5 of 6)
- ✅ Visual Grammar models failed under explicit tests
- ✅ Remaining model is tightly constrained and fragile

**Critical Observations:**
- The sole survivor (Procedural Generation) has a significant prediction failure
- High information density (z=4.00) challenges all "meaningless content" hypotheses
- Visual grammar failure is mechanical (anchor-dependent), not conceptual

### 12.6 Implications for Phase 3

1. **Phase 3 Justification**: Marginal
   - No model survived without caveats
   - Procedural generation survives perturbation but fails information prediction
   - Visual grammar fails operationally but remains conceptually valid

2. **Recommended Path Forward**:
   - Consider **Meaningful Construct** model despite technical falsification
   - Its failure mode (omission/anchor sensitivity) may indicate structural importance
   - Phase 2.2 evidence (z=4.00 info density) supports "hidden meaning" hypothesis

3. **Translation Admissibility**:
   - Remains INADMISSIBLE under natural language framing
   - May be ADMISSIBLE under "meaningful notation" or "index system" framing
   - Further investigation of text-diagram semantic coupling warranted

---

**Phase 2.3 Complete. No definitive survivor. Resolution with integrity achieved.**
