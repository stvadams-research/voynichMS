{
  "provenance": {
    "run_id": "37a44ca7-0a5b-4485-abc9-f738bd02d6a1",
    "git_commit": "41097c90b32d26e807113f1865def2f92e79995e",
    "timestamp": "2026-02-10T20:40:18.217898+00:00",
    "seed": 42,
    "experiment_id": "701f3378-d37c-9c13-acd8-b1040a72761e",
    "run_nonce": 1770756018217425000,
    "command": "run_proximity_uncertainty"
  },
  "results": {
    "target_artifact": "Voynich",
    "parameters": {
      "seed": 42,
      "iterations": 400,
      "dimension_count": 12,
      "bootstrap_dimensions": true,
      "weight_jitter_range": [
        0.85,
        1.15
      ],
      "jackknife_dimensions": true,
      "status_thresholds": {
        "min_nearest_neighbor_stability_for_confirmed": 0.75,
        "min_jackknife_stability_for_confirmed": 0.75,
        "min_rank_stability_for_confirmed": 0.65,
        "min_probability_margin_for_confirmed": 0.1,
        "min_top2_gap_ci_lower_for_confirmed": 0.05,
        "min_nearest_neighbor_stability_for_qualified": 0.5,
        "min_jackknife_stability_for_qualified": 0.7,
        "min_rank_stability_for_qualified": 0.55,
        "min_probability_margin_for_qualified": 0.03,
        "min_top2_set_stability_for_identity_flip_dominant": 0.6,
        "min_rank_entropy_for_high": 1.5
      }
    },
    "status": "INCONCLUSIVE_UNCERTAINTY",
    "reason_code": "TOP2_IDENTITY_FLIP_DOMINANT",
    "allowed_claim": "Comparative claim remains provisional; nearest-neighbor identity is unstable across perturbation lanes.",
    "nearest_neighbor": "Lullian Wheels",
    "nearest_neighbor_distance": 5.0990195135927845,
    "nearest_neighbor_stability": 0.4575,
    "jackknife_nearest_neighbor_stability": 0.8333333333333334,
    "rank_stability": 0.4625,
    "rank_stability_components": {
      "top2_set_stability": 0.595,
      "top3_set_stability": 0.4625,
      "full_ranking_match_rate": 0.0
    },
    "nearest_neighbor_alternative": "Magic Squares",
    "nearest_neighbor_alternative_probability": 0.405,
    "nearest_neighbor_probability_margin": 0.05249999999999999,
    "distance_summary": {
      "Latin": {
        "mean": 8.530438809904128,
        "std": 1.1331439084953776,
        "ci95_lower": 6.31924537741158,
        "ci95_upper": 10.589103830177919,
        "point_estimate": 8.48528137423857,
        "nearest_probability": 0.0075,
        "top3_probability": 0.0675,
        "rank_probability": {
          "1": 0.0075,
          "2": 0.0175,
          "3": 0.0425,
          "4": 0.065,
          "5": 0.25,
          "6": 0.1125,
          "7": 0.1825,
          "8": 0.205,
          "9": 0.1125,
          "10": 0.005
        },
        "expected_rank": 6.335,
        "rank_entropy": 2.7690223703764025
      },
      "Table-Grille": {
        "mean": 8.190630841443832,
        "std": 1.6034724266720932,
        "ci95_lower": 5.206781004495368,
        "ci95_upper": 11.592264873439722,
        "point_estimate": 8.426149773176359,
        "nearest_probability": 0.0025,
        "top3_probability": 0.1525,
        "rank_probability": {
          "1": 0.0025,
          "2": 0.0175,
          "3": 0.1325,
          "4": 0.145,
          "5": 0.2275,
          "6": 0.18,
          "7": 0.0975,
          "8": 0.1825,
          "9": 0.0125,
          "10": 0.0025
        },
        "expected_rank": 5.5125,
        "rank_entropy": 2.7212671936755837
      },
      "Magic Squares": {
        "mean": 5.255037859514,
        "std": 1.510562967424024,
        "ci95_lower": 2.4060361687828378,
        "ci95_upper": 8.052681069012134,
        "point_estimate": 5.5677643628300215,
        "nearest_probability": 0.405,
        "top3_probability": 0.895,
        "rank_probability": {
          "1": 0.405,
          "2": 0.3325,
          "3": 0.1575,
          "4": 0.0575,
          "5": 0.0225,
          "6": 0.02,
          "7": 0.005
        },
        "expected_rank": 2.04,
        "rank_entropy": 1.9874858158352402
      },
      "Vedic Chanting": {
        "mean": 8.29152489478282,
        "std": 1.4861656851620022,
        "ci95_lower": 5.801732724631349,
        "ci95_upper": 11.462538149043421,
        "point_estimate": 8.426149773176359,
        "nearest_probability": 0.0375,
        "top3_probability": 0.1475,
        "rank_probability": {
          "1": 0.0375,
          "2": 0.0325,
          "3": 0.0775,
          "4": 0.11,
          "5": 0.1475,
          "6": 0.1575,
          "7": 0.185,
          "8": 0.0975,
          "9": 0.155
        },
        "expected_rank": 5.9275,
        "rank_entropy": 2.996508354659251
      },
      "Codex Seraph.": {
        "mean": 7.881857604503412,
        "std": 1.0271205973856874,
        "ci95_lower": 5.873587895707259,
        "ci95_upper": 9.900285804069588,
        "point_estimate": 7.937253933193772,
        "nearest_probability": 0.0025,
        "top3_probability": 0.1025,
        "rank_probability": {
          "1": 0.0025,
          "2": 0.0125,
          "3": 0.0875,
          "4": 0.3525,
          "5": 0.1025,
          "6": 0.08,
          "7": 0.145,
          "8": 0.13,
          "9": 0.08,
          "10": 0.0075
        },
        "expected_rank": 5.5425,
        "rank_entropy": 2.6978272659903437
      },
      "Lingua Ignota": {
        "mean": 6.948643854691064,
        "std": 1.81896778050309,
        "ci95_lower": 3.077037708372666,
        "ci95_upper": 10.141690992618907,
        "point_estimate": 7.14142842854285,
        "nearest_probability": 0.0725,
        "top3_probability": 0.55,
        "rank_probability": {
          "1": 0.0725,
          "2": 0.18,
          "3": 0.2975,
          "4": 0.085,
          "5": 0.07,
          "6": 0.0725,
          "7": 0.055,
          "8": 0.0625,
          "9": 0.1025,
          "10": 0.0025
        },
        "expected_rank": 4.2825,
        "rank_entropy": 2.9240461432134337
      },
      "Trithemius": {
        "mean": 8.642055546470162,
        "std": 1.5844875343357252,
        "ci95_lower": 5.36430031336399,
        "ci95_upper": 11.818752027244777,
        "point_estimate": 8.660254037844387,
        "nearest_probability": 0.015,
        "top3_probability": 0.1325,
        "rank_probability": {
          "1": 0.015,
          "2": 0.0325,
          "3": 0.085,
          "4": 0.0625,
          "5": 0.075,
          "6": 0.1575,
          "7": 0.1475,
          "8": 0.1875,
          "9": 0.2125,
          "10": 0.025
        },
        "expected_rank": 6.6,
        "rank_entropy": 2.972066594870525
      },
      "Lullian Wheels": {
        "mean": 4.893475820642579,
        "std": 1.4875286210965464,
        "ci95_lower": 2.435213824678261,
        "ci95_upper": 7.84282442983709,
        "point_estimate": 5.0990195135927845,
        "nearest_probability": 0.4575,
        "top3_probability": 0.9275,
        "rank_probability": {
          "1": 0.4575,
          "2": 0.375,
          "3": 0.095,
          "4": 0.0475,
          "5": 0.015,
          "6": 0.0075,
          "7": 0.0025
        },
        "expected_rank": 1.82,
        "rank_entropy": 1.7436251778817844
      },
      "Penmanship": {
        "mean": 11.958660395178404,
        "std": 1.5692263033737524,
        "ci95_lower": 8.6305082968823,
        "ci95_upper": 14.670868472830872,
        "point_estimate": 11.958260743101398,
        "nearest_probability": 0.0,
        "top3_probability": 0.0,
        "rank_probability": {
          "5": 0.0025,
          "7": 0.0125,
          "8": 0.0075,
          "9": 0.02,
          "10": 0.9575
        },
        "expected_rank": 9.915,
        "rank_entropy": 0.32644531263286414
      },
      "Enochian": {
        "mean": 8.775000079372967,
        "std": 1.6315422137618496,
        "ci95_lower": 5.540400851266518,
        "ci95_upper": 12.13566454062883,
        "point_estimate": 8.94427190999916,
        "nearest_probability": 0.0,
        "top3_probability": 0.025,
        "rank_probability": {
          "3": 0.025,
          "4": 0.075,
          "5": 0.0875,
          "6": 0.2125,
          "7": 0.1675,
          "8": 0.1275,
          "9": 0.305
        },
        "expected_rank": 7.025,
        "rank_entropy": 2.528804296350134
      }
    },
    "ranking_point_estimate": [
      "Lullian Wheels",
      "Magic Squares",
      "Lingua Ignota",
      "Codex Seraph.",
      "Table-Grille",
      "Vedic Chanting",
      "Latin",
      "Trithemius",
      "Enochian",
      "Penmanship"
    ],
    "top2_gap": {
      "mean": 0.9867659771679861,
      "std": 0.7452776358271954,
      "ci95_lower": 0.008482355106459432,
      "ci95_upper": 2.744434565462719
    },
    "top2_gap_fragile": true,
    "fragility_diagnostics": {
      "top2_set_stability": 0.595,
      "top2_identity_flip_rate": 0.405,
      "top2_order_match_rate": 0.3,
      "top2_order_flip_rate": 0.7,
      "nearest_rank_entropy": 1.7436251778817844,
      "runner_up_rank_entropy": 1.9874858158352402,
      "margin_volatility_std": 0.7452776358271954,
      "top2_competition_ratio": 0.8852459016393442,
      "identity_flip_dominant": true,
      "margin_volatility_dominant": false,
      "rank_entropy_high": true,
      "dominant_fragility_signal": "TOP2_IDENTITY_FLIP_DOMINANT"
    },
    "m2_4_closure_lane": "M2_4_BOUNDED",
    "m2_4_reopen_triggers": [
      "Promote to M2_4_ALIGNED only when nearest_neighbor_stability, jackknife_nearest_neighbor_stability, rank_stability, nearest_neighbor_probability_margin, and top2_gap.ci95_lower all clear confirmed thresholds.",
      "Exit bounded lane if confidence diagnostics become incomplete or checker/report entitlement coherence fails."
    ],
    "metric_validity": {
      "required_fields_present": true,
      "missing_required_fields": [],
      "sufficient_iterations": true,
      "status_inputs": {
        "nearest_neighbor_stability": 0.4575,
        "jackknife_nearest_neighbor_stability": 0.8333333333333334,
        "rank_stability": 0.4625,
        "nearest_neighbor_probability_margin": 0.05249999999999999,
        "top2_gap_ci95_lower": 0.008482355106459432
      }
    }
  }
}